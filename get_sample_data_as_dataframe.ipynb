{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE the file name of which csv to modify as variable data\n",
    "# CHANGE working directory as variable wd\n",
    "# CHANGE variable sample_ratio\n",
    "wd = \"/Users/exequielpunzalan/EECS545/project/bigquery-geotab-intersection-congestion/data/data_to_use/\"\n",
    "\n",
    "# data with weather\n",
    "data = pd.read_csv(wd + \"train_with_weather.csv\")\n",
    "data.rename(columns={'Cityid':'CityId'}, inplace=True)\n",
    "\n",
    "# # baseline data\n",
    "# data = pd.read_csv(wd + 'train.csv') # train.csv is from Kaggle\n",
    "# data['CityId'] = ''\n",
    "\n",
    "# remove Philadelphia\n",
    "data = data[data.City!='Philadelphia']\n",
    "data.loc[data.City=='Atlanta','CityId'] = 3\n",
    "data.loc[data.City=='Boston','CityId'] = 2\n",
    "data.loc[data.City=='Chicago','CityId'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>IntersectionId</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>EntryStreetName</th>\n",
       "      <th>ExitStreetName</th>\n",
       "      <th>EntryHeading</th>\n",
       "      <th>ExitHeading</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>TimeFromFirstStop_p50</th>\n",
       "      <th>TimeFromFirstStop_p60</th>\n",
       "      <th>TimeFromFirstStop_p80</th>\n",
       "      <th>DistanceToFirstStop_p20</th>\n",
       "      <th>DistanceToFirstStop_p40</th>\n",
       "      <th>DistanceToFirstStop_p50</th>\n",
       "      <th>DistanceToFirstStop_p60</th>\n",
       "      <th>DistanceToFirstStop_p80</th>\n",
       "      <th>City</th>\n",
       "      <th>CityId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63005</td>\n",
       "      <td>63164</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>...</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "      <td>63714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>61566</td>\n",
       "      <td>61765</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>...</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "      <td>62273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66058</td>\n",
       "      <td>66241</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>...</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "      <td>66834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>63530</td>\n",
       "      <td>63687</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>...</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "      <td>64283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>71662</td>\n",
       "      <td>71863</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>...</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "      <td>72544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>67934</td>\n",
       "      <td>68176</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>...</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "      <td>68770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>69531</td>\n",
       "      <td>69774</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>...</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "      <td>70382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RowId  IntersectionId  Latitude  Longitude  EntryStreetName  \\\n",
       "Month                                                                \n",
       "1        235             235       235        235              235   \n",
       "5         52              52        52         52               52   \n",
       "6      63714           63714     63714      63714            63005   \n",
       "7      62273           62273     62273      62273            61566   \n",
       "8      66834           66834     66834      66834            66058   \n",
       "9      64283           64283     64283      64283            63530   \n",
       "10     72544           72544     72544      72544            71662   \n",
       "11     68770           68770     68770      68770            67934   \n",
       "12     70382           70382     70382      70382            69531   \n",
       "\n",
       "       ExitStreetName  EntryHeading  ExitHeading   Hour  Weekend  ...  \\\n",
       "Month                                                             ...   \n",
       "1                 235           235          235    235      235  ...   \n",
       "5                  52            52           52     52       52  ...   \n",
       "6               63164         63714        63714  63714    63714  ...   \n",
       "7               61765         62273        62273  62273    62273  ...   \n",
       "8               66241         66834        66834  66834    66834  ...   \n",
       "9               63687         64283        64283  64283    64283  ...   \n",
       "10              71863         72544        72544  72544    72544  ...   \n",
       "11              68176         68770        68770  68770    68770  ...   \n",
       "12              69774         70382        70382  70382    70382  ...   \n",
       "\n",
       "       TimeFromFirstStop_p50  TimeFromFirstStop_p60  TimeFromFirstStop_p80  \\\n",
       "Month                                                                        \n",
       "1                        235                    235                    235   \n",
       "5                         52                     52                     52   \n",
       "6                      63714                  63714                  63714   \n",
       "7                      62273                  62273                  62273   \n",
       "8                      66834                  66834                  66834   \n",
       "9                      64283                  64283                  64283   \n",
       "10                     72544                  72544                  72544   \n",
       "11                     68770                  68770                  68770   \n",
       "12                     70382                  70382                  70382   \n",
       "\n",
       "       DistanceToFirstStop_p20  DistanceToFirstStop_p40  \\\n",
       "Month                                                     \n",
       "1                          235                      235   \n",
       "5                           52                       52   \n",
       "6                        63714                    63714   \n",
       "7                        62273                    62273   \n",
       "8                        66834                    66834   \n",
       "9                        64283                    64283   \n",
       "10                       72544                    72544   \n",
       "11                       68770                    68770   \n",
       "12                       70382                    70382   \n",
       "\n",
       "       DistanceToFirstStop_p50  DistanceToFirstStop_p60  \\\n",
       "Month                                                     \n",
       "1                          235                      235   \n",
       "5                           52                       52   \n",
       "6                        63714                    63714   \n",
       "7                        62273                    62273   \n",
       "8                        66834                    66834   \n",
       "9                        64283                    64283   \n",
       "10                       72544                    72544   \n",
       "11                       68770                    68770   \n",
       "12                       70382                    70382   \n",
       "\n",
       "       DistanceToFirstStop_p80   City  CityId  \n",
       "Month                                          \n",
       "1                          235    235     235  \n",
       "5                           52     52      52  \n",
       "6                        63714  63714   63714  \n",
       "7                        62273  62273   62273  \n",
       "8                        66834  66834   66834  \n",
       "9                        64283  64283   64283  \n",
       "10                       72544  72544   72544  \n",
       "11                       68770  68770   68770  \n",
       "12                       70382  70382   70382  \n",
       "\n",
       "[9 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(data.shape)\n",
    "# data.head()\n",
    "# There are only 235 entries from January and 5 entries from May\n",
    "data.groupby(['Month']).count()\n",
    "# dropping January and May entries (don't drop)\n",
    "# data = data[data.Month != 1]\n",
    "# data = data[data.Month != 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2129\n",
      "(7119, 29)\n",
      "973\n",
      "(15745, 29)\n",
      "377\n",
      "(20839, 29)\n"
     ]
    }
   ],
   "source": [
    "# sample unique intersections proportionally\n",
    "\n",
    "sample = pd.DataFrame(columns = data.columns)\n",
    "# ratio/percentage of samples to get/work with\n",
    "# e.g. float(10000)/float(468852) = 0.021\n",
    "sample_ratio = 0.05\n",
    "np.random.seed(1234)\n",
    "\n",
    "for i in [1,2,3]:\n",
    "    IntersectionIds = data.loc[data.CityId==i,'IntersectionId'].unique()\n",
    "    print(len(IntersectionIds))\n",
    "    index = np.random.choice(IntersectionIds, size = int(len(IntersectionIds)*sample_ratio), replace=False)\n",
    "    # in that city and in that intersection\n",
    "    s = data[(data.CityId==i) & (data.IntersectionId.isin(index))]\n",
    "    sample = sample.append(s)\n",
    "    print(sample.shape)\n",
    "\n",
    "# sample.iloc[:20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20839, 29)\n"
     ]
    }
   ],
   "source": [
    "print(sample.shape)\n",
    "new_sample = sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20838, 29)\n"
     ]
    }
   ],
   "source": [
    "# drop the intersection ids whose counts/occurrence are 1\n",
    "IntersectionIds = data.loc[:,'IntersectionId'].unique()\n",
    "intersection_id_counts = sample[\"IntersectionId\"].value_counts().to_dict()\n",
    "drop_ids = [inter_id for inter_id, count in intersection_id_counts.items() if count == 1]\n",
    "drop_ix = []\n",
    "for i in drop_ids:\n",
    "    ix = sample.index[sample['IntersectionId'] == i].tolist()\n",
    "    drop_ix.append(ix[0]) # because there's only 1 occurrence\n",
    "new_sample = sample.drop(drop_ix)\n",
    "print(new_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sample, test_sample = train_test_split(new_sample, test_size=sample_ratio, stratify = new_sample['IntersectionId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping some features and splitting train/test features and labels\n",
    "train_sample = train_sample.dropna()\n",
    "X_train = train_sample.drop(['RowId','EntryStreetName','Path',\n",
    "       'ExitStreetName','TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n",
    "       'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n",
    "       'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n",
    "       'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n",
    "       'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n",
    "       'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n",
    "       'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80'],axis=1)\n",
    "\n",
    "labels = ['TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n",
    "       'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n",
    "       'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n",
    "       'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n",
    "       'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n",
    "       'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n",
    "       'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80']\n",
    "y_train = train_sample[labels]\n",
    "# X_train.rename(columns={'Cityid':'CityId'}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test_sample.dropna()\n",
    "X_test = test_sample.drop(['RowId','EntryStreetName','Path',\n",
    "       'ExitStreetName','TotalTimeStopped_p20', 'TotalTimeStopped_p40',\n",
    "       'TotalTimeStopped_p50', 'TotalTimeStopped_p60', 'TotalTimeStopped_p80',\n",
    "       'TimeFromFirstStop_p20', 'TimeFromFirstStop_p40',\n",
    "       'TimeFromFirstStop_p50', 'TimeFromFirstStop_p60',\n",
    "       'TimeFromFirstStop_p80', 'DistanceToFirstStop_p20',\n",
    "       'DistanceToFirstStop_p40', 'DistanceToFirstStop_p50',\n",
    "       'DistanceToFirstStop_p60', 'DistanceToFirstStop_p80'],axis=1)\n",
    "y_test = test_sample[labels]\n",
    "# X_test.rename(columns={'Cityid':'CityId'}, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/EECS545-env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Applications/anaconda/envs/EECS545-env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# OHE\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# drop City column (don't rerun)\n",
    "X_train = X_train.drop(['City'], axis=1)\n",
    "X_test = X_test.drop(['City'], axis=1)\n",
    "    \n",
    "# which ones are categorical features\n",
    "categorical_cols = ['CityId','EntryHeading', 'ExitHeading']\n",
    "categorical_feature_mask = [True if c in categorical_cols else False for c in X_train.columns]\n",
    "categorical_feature_mask = pd.Series(data=categorical_feature_mask, index=X_train.columns)\n",
    "\n",
    "# label encoding\n",
    "encoder_train = LabelEncoder()\n",
    "X_train[categorical_cols] = X_train[categorical_cols].apply(encoder_train.fit_transform)\n",
    "encoder_test = LabelEncoder()\n",
    "X_test[categorical_cols] = X_test[categorical_cols].apply(encoder_test.fit_transform)\n",
    "\n",
    "\n",
    "# instantiate OneHotEncoder on categ cols only\n",
    "# categorical_features = boolean mask for categorical columns\n",
    "# sparse = False output an array not sparse matrix\n",
    "# ohe = OneHotEncoder(categorical_features = categorical_feature_mask, sparse=False) \n",
    "ohe = OneHotEncoder(sparse=False) \n",
    "# apply OneHotEncoder on categorical feature columns\n",
    "X_ohe_train_ary = ohe.fit_transform(X_train[categorical_cols]) # returns a numpy array\n",
    "X_ohe_test_ary = ohe.fit_transform(X_test[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n",
      "[5 0 1 7 6 4 3 2]\n",
      "[5 4 7 0 3 6 2 1]\n",
      "(19355, 9)\n",
      "(1020, 9)\n",
      "(19355, 19)\n",
      "(1020, 19)\n"
     ]
    }
   ],
   "source": [
    "# expect 19 additional columns to original data because of OHE, while dropping categorical columns\n",
    "print(X_train[\"CityId\"].unique()) # 3 unique\n",
    "print(X_train[\"EntryHeading\"].unique()) # 8 unique\n",
    "print(X_train[\"ExitHeading\"].unique()) # 8 unique\n",
    "# shape of dataframes and np array\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# print(X_train[categorical_cols].shape)\n",
    "# print(X_test[categorical_cols].shape)\n",
    "print(X_ohe_train_ary.shape)\n",
    "print(X_ohe_test_ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append OHE vectors to dataframes\n",
    "num_unique_CityId = len(X_train[\"CityId\"].unique())\n",
    "num_unique_EntryHeading = len(X_train[\"EntryHeading\"].unique())\n",
    "num_unique_ExitHeading = len(X_train[\"ExitHeading\"].unique())\n",
    "\n",
    "for i in range(num_unique_CityId):\n",
    "    # add new column where the column has 0/1 values for that feature\n",
    "    X_train[categorical_cols[0] + str(i)] = X_ohe_train_ary[:, i]\n",
    "    X_test[categorical_cols[0] + str(i)] = X_ohe_test_ary[:, i]\n",
    "for i in range(num_unique_EntryHeading):\n",
    "    X_train[categorical_cols[1] + str(i)] = X_ohe_train_ary[:, i+num_unique_CityId]\n",
    "    X_test[categorical_cols[1] + str(i)] = X_ohe_test_ary[:, i+num_unique_CityId]\n",
    "for i in range(num_unique_ExitHeading):\n",
    "    X_train[categorical_cols[2] + str(i)] = X_ohe_train_ary[:, i+num_unique_CityId+num_unique_EntryHeading]\n",
    "    X_test[categorical_cols[2] + str(i)] = X_ohe_test_ary[:, i+num_unique_CityId+num_unique_EntryHeading]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19355, 25)\n",
      "(1020, 25)\n",
      "(19355, 15)\n",
      "(1020, 15)\n"
     ]
    }
   ],
   "source": [
    "# sort column names and save to csv\n",
    "X_train = X_train.reindex(sorted(X_train.columns), axis=1)\n",
    "X_train = X_train.drop(categorical_cols, axis=1)\n",
    "X_test = X_test.reindex(sorted(X_test.columns), axis=1)\n",
    "X_test = X_test.drop(categorical_cols, axis=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "X_train.head(10)\n",
    "# saving\n",
    "X_train.to_csv(wd + \"formatted_train_data_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "X_test.to_csv(wd + \"formatted_test_data_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "y_train.to_csv(wd + \"formatted_train_labels_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "y_test.to_csv(wd + \"formatted_test_labels_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "\n",
    "# X_train.to_csv(wd + \"baseline_train_data_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "# X_test.to_csv(wd + \"baseline_test_data_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "# y_train.to_csv(wd + \"baseline_train_labels_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)\n",
    "# y_test.to_csv(wd + \"baseline_test_labels_sampleratio{}.csv\".format(sample_ratio), encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EECS545-env-py37",
   "language": "python",
   "name": "eecs545-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
